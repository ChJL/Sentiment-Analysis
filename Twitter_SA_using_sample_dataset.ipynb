{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/chieh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"TWID\",\"TEXT\",\"VALUE\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file: ./data/twitt_sample.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = os.listdir(\"./data\")[1]\n",
    "dataset_path = os.path.join(\"./\",\"data\",dataset_filename)\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING ,\n",
    "                 lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 258322\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.467811e+09</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.467814e+09</td>\n",
       "      <td>one of my friend called me, and asked to meet ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.467817e+09</td>\n",
       "      <td>@MissXu sorry! bed time came here (GMT+1)   ht...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.467822e+09</td>\n",
       "      <td>@andywana Not sure what they are, only that th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.467825e+09</td>\n",
       "      <td>@katortiz  Not forever... See you soon!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.467826e+09</td>\n",
       "      <td>Why won't you show my location?!   http://twit...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.467834e+09</td>\n",
       "      <td>i think my arms are sore from tennis</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.467841e+09</td>\n",
       "      <td>@allyheman but.. but.. but.. I'm not a big fan...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.467843e+09</td>\n",
       "      <td>@ozesteph1992 Shame to hear this Stephan</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TWID                                               TEXT  VALUE\n",
       "0  1.467811e+09  @Kenichan I dived many times for the ball. Man...     -1\n",
       "1  1.467811e+09  @nationwideclass no, it's not behaving at all....     -1\n",
       "2  1.467814e+09  one of my friend called me, and asked to meet ...     -1\n",
       "3  1.467817e+09  @MissXu sorry! bed time came here (GMT+1)   ht...     -1\n",
       "4  1.467822e+09  @andywana Not sure what they are, only that th...     -1\n",
       "5  1.467825e+09            @katortiz  Not forever... See you soon!     -1\n",
       "6  1.467826e+09  Why won't you show my location?!   http://twit...     -1\n",
       "7  1.467834e+09              i think my arms are sore from tennis      -1\n",
       "8  1.467841e+09  @allyheman but.. but.. but.. I'm not a big fan...     -1\n",
       "9  1.467843e+09          @ozesteph1992 Shame to hear this Stephan      -1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {-1: \"NEGATIVE\", 0: \"NEUTRAL\", 1: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.5 ms, sys: 4.6 ms, total: 94.1 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.VALUE = df.VALUE.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(df.VALUE)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.97 s, sys: 91 ms, total: 8.07 s\n",
      "Wall time: 8.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.TEXT = df.TEXT.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dived many times ball managed save 50 rest go ...\n",
       "1                                     behaving mad see\n",
       "2    one friend called asked meet mid valley today ...\n",
       "3                            sorry bed time came gmt 1\n",
       "4    sure pos much want dont think trade away compa...\n",
       "5                                     forever see soon\n",
       "6                                        show location\n",
       "7                               think arms sore tennis\n",
       "8                                big fan camilla belle\n",
       "9                                   shame hear stephan\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TEXT.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 206657\n",
      "TEST size: 51665\n"
     ]
    }
   ],
   "source": [
    "# split train, test data \n",
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82347</th>\n",
       "      <td>1.553709e+09</td>\n",
       "      <td>writing</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127981</th>\n",
       "      <td>2.000995e+09</td>\n",
       "      <td>tons followers follow</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237873</th>\n",
       "      <td>8.006250e+17</td>\n",
       "      <td>happy monday hope smashing week happymonday mo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>1.470041e+09</td>\n",
       "      <td>made ontd entry also happens flocked</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100674</th>\n",
       "      <td>1.880255e+09</td>\n",
       "      <td>glad developed test suite amberdms billing sys...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TWID                                               TEXT  \\\n",
       "82347   1.553709e+09                                            writing   \n",
       "127981  2.000995e+09                              tons followers follow   \n",
       "237873  8.006250e+17  happy monday hope smashing week happymonday mo...   \n",
       "821     1.470041e+09               made ontd entry also happens flocked   \n",
       "100674  1.880255e+09  glad developed test suite amberdms billing sys...   \n",
       "\n",
       "           VALUE  \n",
       "82347   POSITIVE  \n",
       "127981  POSITIVE  \n",
       "237873  POSITIVE  \n",
       "821     NEGATIVE  \n",
       "100674  POSITIVE  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 2 vec\n",
    "documents = [_text.split() for _text in df_train.TEXT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writing']\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 12:28:24,159 : INFO : collecting all words and their counts\n",
      "2020-11-19 12:28:24,161 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-11-19 12:28:24,203 : INFO : PROGRESS: at sentence #10000, processed 72495 words, keeping 17777 word types\n",
      "2020-11-19 12:28:24,237 : INFO : PROGRESS: at sentence #20000, processed 145452 words, keeping 27973 word types\n",
      "2020-11-19 12:28:24,265 : INFO : PROGRESS: at sentence #30000, processed 218901 words, keeping 36356 word types\n",
      "2020-11-19 12:28:24,289 : INFO : PROGRESS: at sentence #40000, processed 291426 words, keeping 43945 word types\n",
      "2020-11-19 12:28:24,311 : INFO : PROGRESS: at sentence #50000, processed 364256 words, keeping 50892 word types\n",
      "2020-11-19 12:28:24,337 : INFO : PROGRESS: at sentence #60000, processed 436645 words, keeping 57170 word types\n",
      "2020-11-19 12:28:24,363 : INFO : PROGRESS: at sentence #70000, processed 509358 words, keeping 62997 word types\n",
      "2020-11-19 12:28:24,385 : INFO : PROGRESS: at sentence #80000, processed 581586 words, keeping 68732 word types\n",
      "2020-11-19 12:28:24,408 : INFO : PROGRESS: at sentence #90000, processed 653953 words, keeping 74115 word types\n",
      "2020-11-19 12:28:24,428 : INFO : PROGRESS: at sentence #100000, processed 726634 words, keeping 79307 word types\n",
      "2020-11-19 12:28:24,460 : INFO : PROGRESS: at sentence #110000, processed 798484 words, keeping 84279 word types\n",
      "2020-11-19 12:28:24,482 : INFO : PROGRESS: at sentence #120000, processed 871154 words, keeping 89313 word types\n",
      "2020-11-19 12:28:24,506 : INFO : PROGRESS: at sentence #130000, processed 943255 words, keeping 94073 word types\n",
      "2020-11-19 12:28:24,542 : INFO : PROGRESS: at sentence #140000, processed 1015832 words, keeping 98681 word types\n",
      "2020-11-19 12:28:24,561 : INFO : PROGRESS: at sentence #150000, processed 1088303 words, keeping 103204 word types\n",
      "2020-11-19 12:28:24,583 : INFO : PROGRESS: at sentence #160000, processed 1160891 words, keeping 107679 word types\n",
      "2020-11-19 12:28:24,606 : INFO : PROGRESS: at sentence #170000, processed 1233488 words, keeping 112083 word types\n",
      "2020-11-19 12:28:24,629 : INFO : PROGRESS: at sentence #180000, processed 1306513 words, keeping 116422 word types\n",
      "2020-11-19 12:28:24,664 : INFO : PROGRESS: at sentence #190000, processed 1378945 words, keeping 120643 word types\n",
      "2020-11-19 12:28:24,687 : INFO : PROGRESS: at sentence #200000, processed 1451682 words, keeping 124890 word types\n",
      "2020-11-19 12:28:24,700 : INFO : collected 127526 word types from a corpus of 1499974 raw words and 206657 sentences\n",
      "2020-11-19 12:28:24,701 : INFO : Loading a fresh vocabulary\n",
      "2020-11-19 12:28:24,769 : INFO : effective_min_count=10 retains 12531 unique words (9% of original 127526, drops 114995)\n",
      "2020-11-19 12:28:24,769 : INFO : effective_min_count=10 leaves 1302341 word corpus (86% of original 1499974, drops 197633)\n",
      "2020-11-19 12:28:24,810 : INFO : deleting the raw counts dictionary of 127526 items\n",
      "2020-11-19 12:28:24,813 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2020-11-19 12:28:24,814 : INFO : downsampling leaves estimated 1239966 word corpus (95.2% of prior 1302341)\n",
      "2020-11-19 12:28:24,851 : INFO : estimated required memory for 12531 words and 300 dimensions: 36339900 bytes\n",
      "2020-11-19 12:28:24,852 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 12531\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 12:28:53,249 : INFO : training model with 8 workers on 12531 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2020-11-19 12:28:54,314 : INFO : EPOCH 1 - PROGRESS: at 68.00% examples, 842204 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:28:54,653 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:28:54,689 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:28:54,691 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:28:54,692 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:28:54,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:28:54,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:28:54,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:28:54,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:28:54,744 : INFO : EPOCH - 1 : training on 1499974 raw words (1239778 effective words) took 1.4s, 866435 effective words/s\n",
      "2020-11-19 12:28:55,758 : INFO : EPOCH 2 - PROGRESS: at 71.35% examples, 883393 words/s, in_qsize 11, out_qsize 4\n",
      "2020-11-19 12:28:56,068 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:28:56,069 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:28:56,073 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:28:56,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:28:56,103 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:28:56,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:28:56,113 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:28:56,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:28:56,118 : INFO : EPOCH - 2 : training on 1499974 raw words (1239842 effective words) took 1.4s, 910690 effective words/s\n",
      "2020-11-19 12:28:57,143 : INFO : EPOCH 3 - PROGRESS: at 68.00% examples, 830202 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:28:57,520 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:28:57,521 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:28:57,524 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:28:57,532 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:28:57,549 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:28:57,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:28:57,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:28:57,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:28:57,575 : INFO : EPOCH - 3 : training on 1499974 raw words (1239913 effective words) took 1.4s, 855933 effective words/s\n",
      "2020-11-19 12:28:58,590 : INFO : EPOCH 4 - PROGRESS: at 71.33% examples, 880674 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:28:58,906 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:28:58,908 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:28:58,951 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:28:58,953 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:28:58,964 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:28:58,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:28:59,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:28:59,023 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:28:59,024 : INFO : EPOCH - 4 : training on 1499974 raw words (1240118 effective words) took 1.4s, 862053 effective words/s\n",
      "2020-11-19 12:29:00,068 : INFO : EPOCH 5 - PROGRESS: at 71.32% examples, 856446 words/s, in_qsize 12, out_qsize 4\n",
      "2020-11-19 12:29:00,377 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:00,378 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:00,394 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:00,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:00,423 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:00,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:00,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:00,460 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:00,461 : INFO : EPOCH - 5 : training on 1499974 raw words (1239806 effective words) took 1.4s, 869714 effective words/s\n",
      "2020-11-19 12:29:01,483 : INFO : EPOCH 6 - PROGRESS: at 72.00% examples, 885923 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:01,810 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:01,811 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:01,812 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:01,822 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:01,837 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:01,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:01,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:01,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:01,887 : INFO : EPOCH - 6 : training on 1499974 raw words (1239906 effective words) took 1.4s, 878316 effective words/s\n",
      "2020-11-19 12:29:02,908 : INFO : EPOCH 7 - PROGRESS: at 71.34% examples, 876791 words/s, in_qsize 13, out_qsize 2\n",
      "2020-11-19 12:29:03,225 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:03,231 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:03,240 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:03,241 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:03,246 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:03,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:03,282 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:03,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:03,291 : INFO : EPOCH - 7 : training on 1499974 raw words (1239748 effective words) took 1.4s, 890902 effective words/s\n",
      "2020-11-19 12:29:04,327 : INFO : EPOCH 8 - PROGRESS: at 66.64% examples, 807986 words/s, in_qsize 12, out_qsize 3\n",
      "2020-11-19 12:29:04,788 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:04,790 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:04,791 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:04,792 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:04,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:04,872 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:04,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:04,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:04,905 : INFO : EPOCH - 8 : training on 1499974 raw words (1239972 effective words) took 1.6s, 774319 effective words/s\n",
      "2020-11-19 12:29:05,931 : INFO : EPOCH 9 - PROGRESS: at 43.94% examples, 538604 words/s, in_qsize 16, out_qsize 2\n",
      "2020-11-19 12:29:06,895 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:06,917 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 12:29:06,918 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:06,927 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:06,928 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:06,939 : INFO : EPOCH 9 - PROGRESS: at 98.68% examples, 605578 words/s, in_qsize 2, out_qsize 1\n",
      "2020-11-19 12:29:06,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:06,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:06,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:06,954 : INFO : EPOCH - 9 : training on 1499974 raw words (1239768 effective words) took 2.0s, 609056 effective words/s\n",
      "2020-11-19 12:29:07,968 : INFO : EPOCH 10 - PROGRESS: at 57.96% examples, 716393 words/s, in_qsize 14, out_qsize 1\n",
      "2020-11-19 12:29:08,526 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:08,527 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:08,528 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:08,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:08,536 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:08,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:08,580 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:08,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:08,581 : INFO : EPOCH - 10 : training on 1499974 raw words (1240307 effective words) took 1.6s, 767130 effective words/s\n",
      "2020-11-19 12:29:09,610 : INFO : EPOCH 11 - PROGRESS: at 66.66% examples, 812250 words/s, in_qsize 16, out_qsize 1\n",
      "2020-11-19 12:29:10,012 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:10,031 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:10,034 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:10,043 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:10,051 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:10,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:10,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:10,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:10,059 : INFO : EPOCH - 11 : training on 1499974 raw words (1239954 effective words) took 1.5s, 845507 effective words/s\n",
      "2020-11-19 12:29:11,080 : INFO : EPOCH 12 - PROGRESS: at 59.29% examples, 728160 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:11,556 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:11,564 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:11,573 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:11,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:11,580 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:11,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:11,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:11,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:11,602 : INFO : EPOCH - 12 : training on 1499974 raw words (1240034 effective words) took 1.5s, 809180 effective words/s\n",
      "2020-11-19 12:29:12,630 : INFO : EPOCH 13 - PROGRESS: at 59.96% examples, 730165 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:13,156 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:13,159 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:13,175 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:13,184 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:13,198 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:13,201 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:13,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:13,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:13,206 : INFO : EPOCH - 13 : training on 1499974 raw words (1240426 effective words) took 1.6s, 777365 effective words/s\n",
      "2020-11-19 12:29:14,242 : INFO : EPOCH 14 - PROGRESS: at 64.67% examples, 787853 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:14,719 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:14,720 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:14,726 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:14,744 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:14,748 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:14,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:14,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:14,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:14,756 : INFO : EPOCH - 14 : training on 1499974 raw words (1239991 effective words) took 1.5s, 809345 effective words/s\n",
      "2020-11-19 12:29:15,801 : INFO : EPOCH 15 - PROGRESS: at 65.31% examples, 783139 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:16,274 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:16,275 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:16,277 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:16,278 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:16,289 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:16,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:16,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:16,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:16,311 : INFO : EPOCH - 15 : training on 1499974 raw words (1239885 effective words) took 1.5s, 802511 effective words/s\n",
      "2020-11-19 12:29:17,325 : INFO : EPOCH 16 - PROGRESS: at 68.00% examples, 840802 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:17,719 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:17,741 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:17,751 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:17,757 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:17,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:17,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:17,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:17,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:17,791 : INFO : EPOCH - 16 : training on 1499974 raw words (1239934 effective words) took 1.5s, 844093 effective words/s\n",
      "2020-11-19 12:29:18,814 : INFO : EPOCH 17 - PROGRESS: at 53.98% examples, 664478 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:19,454 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:19,466 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:19,471 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:19,476 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:19,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 12:29:19,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:19,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:19,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:19,506 : INFO : EPOCH - 17 : training on 1499974 raw words (1240154 effective words) took 1.7s, 729538 effective words/s\n",
      "2020-11-19 12:29:20,551 : INFO : EPOCH 18 - PROGRESS: at 66.67% examples, 799406 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:20,993 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:20,997 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:21,023 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:21,027 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:21,036 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:21,043 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:21,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:21,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:21,054 : INFO : EPOCH - 18 : training on 1499974 raw words (1240091 effective words) took 1.5s, 806239 effective words/s\n",
      "2020-11-19 12:29:22,070 : INFO : EPOCH 19 - PROGRESS: at 65.33% examples, 806445 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:22,498 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:22,501 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:22,508 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:22,510 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:22,511 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:22,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:22,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:22,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:22,541 : INFO : EPOCH - 19 : training on 1499974 raw words (1240296 effective words) took 1.5s, 840857 effective words/s\n",
      "2020-11-19 12:29:23,553 : INFO : EPOCH 20 - PROGRESS: at 71.32% examples, 884074 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:23,875 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:23,879 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:23,883 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:23,885 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:23,893 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:23,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:23,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:23,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:23,907 : INFO : EPOCH - 20 : training on 1499974 raw words (1240221 effective words) took 1.4s, 915392 effective words/s\n",
      "2020-11-19 12:29:25,010 : INFO : EPOCH 21 - PROGRESS: at 47.27% examples, 537751 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:25,947 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:25,948 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:25,955 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:25,962 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:25,964 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:25,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:25,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:25,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:25,988 : INFO : EPOCH - 21 : training on 1499974 raw words (1240099 effective words) took 2.1s, 599008 effective words/s\n",
      "2020-11-19 12:29:27,043 : INFO : EPOCH 22 - PROGRESS: at 65.33% examples, 801253 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:27,571 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:27,572 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:27,579 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:27,580 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:27,581 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:27,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:27,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:27,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:27,602 : INFO : EPOCH - 22 : training on 1499974 raw words (1240035 effective words) took 1.6s, 789677 effective words/s\n",
      "2020-11-19 12:29:28,620 : INFO : EPOCH 23 - PROGRESS: at 66.66% examples, 822121 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:29,092 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:29,093 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:29,097 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:29,102 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:29,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:29,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:29,122 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:29,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:29,126 : INFO : EPOCH - 23 : training on 1499974 raw words (1239832 effective words) took 1.5s, 820293 effective words/s\n",
      "2020-11-19 12:29:30,156 : INFO : EPOCH 24 - PROGRESS: at 67.99% examples, 828862 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:30,524 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:30,549 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:30,563 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:30,573 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:30,576 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:30,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:30,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:30,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:30,600 : INFO : EPOCH - 24 : training on 1499974 raw words (1240015 effective words) took 1.5s, 848792 effective words/s\n",
      "2020-11-19 12:29:31,614 : INFO : EPOCH 25 - PROGRESS: at 69.99% examples, 866276 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:31,925 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:31,944 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:31,963 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:31,982 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:31,987 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:32,007 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:32,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:32,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:32,018 : INFO : EPOCH - 25 : training on 1499974 raw words (1240274 effective words) took 1.4s, 882588 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 12:29:33,042 : INFO : EPOCH 26 - PROGRESS: at 68.68% examples, 849768 words/s, in_qsize 16, out_qsize 1\n",
      "2020-11-19 12:29:33,376 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:33,394 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:33,400 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:33,409 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:33,417 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:33,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:33,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:33,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:33,434 : INFO : EPOCH - 26 : training on 1499974 raw words (1239953 effective words) took 1.4s, 889296 effective words/s\n",
      "2020-11-19 12:29:34,447 : INFO : EPOCH 27 - PROGRESS: at 73.33% examples, 904187 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:34,791 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:34,799 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:34,809 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:34,820 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:34,823 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:34,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:34,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:34,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:34,871 : INFO : EPOCH - 27 : training on 1499974 raw words (1239834 effective words) took 1.4s, 867834 effective words/s\n",
      "2020-11-19 12:29:35,893 : INFO : EPOCH 28 - PROGRESS: at 63.31% examples, 778998 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:36,365 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:36,366 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:36,377 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:36,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:36,404 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:36,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:36,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:36,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:36,420 : INFO : EPOCH - 28 : training on 1499974 raw words (1239983 effective words) took 1.5s, 808023 effective words/s\n",
      "2020-11-19 12:29:37,436 : INFO : EPOCH 29 - PROGRESS: at 70.66% examples, 873285 words/s, in_qsize 16, out_qsize 0\n",
      "2020-11-19 12:29:37,845 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:37,880 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:37,881 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:37,900 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:37,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:37,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:37,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:37,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:37,924 : INFO : EPOCH - 29 : training on 1499974 raw words (1239779 effective words) took 1.5s, 831164 effective words/s\n",
      "2020-11-19 12:29:38,946 : INFO : EPOCH 30 - PROGRESS: at 69.33% examples, 853489 words/s, in_qsize 14, out_qsize 2\n",
      "2020-11-19 12:29:39,275 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:39,302 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:39,305 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:39,336 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:39,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:39,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:39,351 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:39,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:39,355 : INFO : EPOCH - 30 : training on 1499974 raw words (1240012 effective words) took 1.4s, 875623 effective words/s\n",
      "2020-11-19 12:29:40,373 : INFO : EPOCH 31 - PROGRESS: at 70.00% examples, 863595 words/s, in_qsize 15, out_qsize 0\n",
      "2020-11-19 12:29:40,742 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:40,753 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:40,757 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:40,757 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:40,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:40,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:40,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:40,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:40,799 : INFO : EPOCH - 31 : training on 1499974 raw words (1239921 effective words) took 1.4s, 866530 effective words/s\n",
      "2020-11-19 12:29:41,828 : INFO : EPOCH 32 - PROGRESS: at 70.00% examples, 855506 words/s, in_qsize 14, out_qsize 1\n",
      "2020-11-19 12:29:42,185 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-11-19 12:29:42,198 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-11-19 12:29:42,199 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-11-19 12:29:42,213 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-11-19 12:29:42,219 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-19 12:29:42,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-19 12:29:42,240 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-19 12:29:42,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-19 12:29:42,254 : INFO : EPOCH - 32 : training on 1499974 raw words (1239795 effective words) took 1.4s, 860852 effective words/s\n",
      "2020-11-19 12:29:42,254 : INFO : training on a 47999168 raw words (39679676 effective words) took 49.0s, 809729 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 1.34 s, total: 2min 25s\n",
      "Wall time: 49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39679676, 47999168)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chieh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-11-19 12:30:58,668 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('luv', 0.4769320785999298),\n",
       " ('loved', 0.43217742443084717),\n",
       " ('loves', 0.41431283950805664),\n",
       " ('lovee', 0.36954134702682495),\n",
       " ('thankful', 0.3435690999031067),\n",
       " ('demi', 0.34211021661758423),\n",
       " ('mileycyrus', 0.33798059821128845),\n",
       " ('ily', 0.33211320638656616),\n",
       " ('adore', 0.32305991649627686),\n",
       " ('loooove', 0.3196525573730469)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 127527\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.TEXT)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.TEXT), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.TEXT), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE', 'NEUTRAL']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoder\n",
    "labels = df_train.VALUE.unique().tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (206657, 1)\n",
      "y_test (51665, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.VALUE.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.VALUE.tolist())\n",
    "y_test = encoder.transform(df_test.VALUE.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (206657, 300)\n",
      "y_train (206657, 1)\n",
      "x_test (51665, 300)\n",
      "y_test (51665, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127527, 300)\n"
     ]
    }
   ],
   "source": [
    "# Embedding Layer\n",
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          38258100  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 38,418,601\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 38,258,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build Model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "182/182 [==============================] - ETA: 0s - loss: -3.1005 - accuracy: 0.2818WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 13:03:57,848 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1345s 7s/step - loss: -3.1005 - accuracy: 0.2818 - val_loss: -6.3541 - val_accuracy: 0.3282\n",
      "Epoch 2/8\n",
      "182/182 [==============================] - ETA: 0s - loss: -8.6341 - accuracy: 0.3325WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 13:26:48,150 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1363s 7s/step - loss: -8.6341 - accuracy: 0.3325 - val_loss: -12.1032 - val_accuracy: 0.3398\n",
      "Epoch 3/8\n",
      " 95/182 [==============>...............] - ETA: 10:27 - loss: -12.3368 - accuracy: 0.3303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d2e35c6407ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 24s 1s/step - loss: -14.6257 - accuracy: 0.3346\n",
      "\n",
      "ACCURACY: 0.3346075713634491\n",
      "LOSS: -14.625689506530762\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-009b49b152a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'POSITIVE', 'score': 1.0, 'elapsed_time': 0.38455700874328613}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I love the music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'POSITIVE', 'score': 1.0, 'elapsed_time': 0.09198284149169922}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i don't know what i'm doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEUTRAL',\n",
       " 'score': 0.4151146709918976,\n",
       " 'elapsed_time': 0.0899190902709961}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I hate the rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE',\n",
       " 'score': 0.1445106565952301,\n",
       " 'elapsed_time': 0.09254717826843262}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Bad guys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'POSITIVE',\n",
       " 'score': 0.9558982253074646,\n",
       " 'elapsed_time': 0.07656407356262207}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"fuck u all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 13:45:07,272 : INFO : saving Word2Vec object under model.w2v, separately None\n",
      "2020-11-19 13:45:07,274 : INFO : not storing attribute vectors_norm\n",
      "2020-11-19 13:45:07,275 : INFO : not storing attribute cum_table\n",
      "2020-11-19 13:45:07,705 : INFO : saved model.w2v\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
